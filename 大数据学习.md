# 大数据学习

## 1.大数据概论

### 大数据概念

![image-20200928153446282](C:\Users\MNH\AppData\Roaming\Typora\typora-user-images\image-20200928153446282.png)

主要解决，海量数据的存储和海量数据的分析计算问题

------

### 大数据的特点

4个v：

#### 1.Volume（大量）

#### 2.Velocity（高速）

#### 3.Variety（多样）

#### 4.Value（低价值密度）

------

### 大数据应用场景

#### 1.物流仓储

大数据分析系统助力商家精细化运营、提升销量、节约成本

#### 2.零售

分析用户消费习惯，为用户购买商品提供方便，从而提升商品销量

#### 3.旅游

深度结合大数据能力与旅游行业需求，共建旅游产业智慧管理、智慧服务和智慧营销的未来

#### 4.商品广告推荐

给用户推荐可能喜欢的商品

#### 5.保险

海量数据挖掘及风险预测，助力保险行业精准营销，提升精细化定价能力

#### 6.金融

多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险

#### 7.房产

大数据全面助力房地产行业，打造精准投策与营销，选出更合适的地，建造更合适的楼，卖给更合适的人

#### 8.人工智能

------

### 大数据部门业务流程分析

------

![image-20200928164617251](C:\Users\MNH\AppData\Roaming\Typora\typora-user-images\image-20200928164617251.png)

### 大数据部门组织结构

![大数据部门组织结构](C:\Users\MNH\Desktop\大数据部门组织结构.png)

## 2.从Hadoop框架讨论大数据生态

### Hadoop是什么

1.Hadoop是一个由Apache基金会所开发的分布式系统基础架构

2.主要解决，海量数据的存储和海量数据的分析计算

3.广义上来说，Hadoop通常指一个更广泛的概念----Hadoop生态圈

![img](http://dingyue.ws.126.net/VHRlRhxkoV1gTr2cypN7azWQvfYBmaMCHf418iP8uTwyk1529391468494.jpg)

### Hadoop发行版本

Apache、Cloudera、Hortonworks

### Hadoop的优势

1. 高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失
2. 搞扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点
3. 高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度
4. 高容错性：它能将失败的任务重新分配

### Hadoop的组成

#### Hadoop1.x和2.x的区别

Hadoop1.x组成：

- Common（辅助工具）
- HDFS（数据存储）
- MapReduce（计算+资源调度）

Hadoop2.x组成：

- Common（辅助工具）
- HDFS（数据存储）
- Yarn（资源调度）
- MapReduce（计算）

在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大；Hadoop2.x时代,增加了Yarn，Yarn只负责资源的调度，MapReduce只负责运算。

#### HDFS架构概述

1. NameNode(nn):存储文件的原数据，如：文件名、文件目录结构、文件属性以及每个文件的块列表和块所在的DataNode
2. DataNode(dn):在本地文件系统存储文件块数据，以及块数据的校验和
3. Secondary NameNode(2nn):用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照

#### Yarn的架构概述

![image-20201003212835587](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201003212835587.png)

1. Resource Manager（RM）主要作用如下：
   - 处理客户端请求
   - 监控NodeManager
   - 启动或监控ApplicationMaster
   - 资源的分配与调度
2. Node Manager（NM）主要作用如下：
   - 管理单个节点上的资源
   - 处理来自ResourceManager上的命令
   - 处理来自ApplicationMaster上的命令
3. ApplicationMaster（AM）作用如下
   - 负责数据的切分
   - 为应用程序申请资源并分配给内部任务
   - 任务的监控与容错
4. Container

Container是YARN中的资源的抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘网络等



#### MapReduce架构概述

MapReduce将计算过程分为两个阶段：Map和Reduce

1. Map阶段并行处理输入数据
2. Reduce阶段对Map结果进行汇总

### 大数据技术生态体系

![image-20201003232314683](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201003232314683.png)

## 3.Hadoop运行环境搭建

### 1.虚拟机环境的准备

#### 1.1.版本

我OS选择的是Centos6.5版本 链接如下：

http://mirror.nsc.liu.se/centos-store/6.5/isos/x86_64/

JDK版本为1.8版本的

hadoop版本为2.7.3

其中JDK和hadoop的链接在百度网盘

链接：https://pan.baidu.com/s/1WuLMIjpE1rU0-Tb9dXuLuw 
提取码：IMLK 

#### 1.2.虚拟机基础设置

由于在默认情况下centos6.5里有自带的jdk1.7版本，所以我们需要自定义安装

新建虚拟机选择典型模式

![新建虚拟机-选中典型模式](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015150841045.png)

选择稍后安装操作系统

![稍后安装操作系统](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015151004139.png)

选中Linux，版本选择为Centos6 64位

![image-20201015151120511](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015151120511.png)

选择安装位置，默认是C盘，可以根据自己的需要更改安装位置，我选择了D盘，将虚拟机命名为Neo4j，这是由于我之后需要搭建Neo4j集群，一般情况下命名为hadoop

指定磁盘容量，一般是20G，选择将虚拟磁盘存储为单个文件

![image-20201015151536824](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015151536824.png)

自定义硬件

虚拟机内存选择为2G，虚拟安装完成之后可以自己更改

![image-20201015151749609](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015151749609.png)

处理器数量以及处理器内核的数量，看自己心情，没有明确要求

![image-20201015151921711](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015151921711.png)

使用我们已经下载好的Centos6.5版本

![image-20201015152010584](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015152010584.png)

之后点击关闭，点击完成，进入如下界面，开启虚拟机，等待60秒左右，进行后续操作

![image-20201015152223561](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015152223561.png)

#### 1.3.虚拟机的基本功能配置

进入如下界面，直接选择Skip(如果选择OK，会扫描很长时间，有点浪费时间)

![image-20201015152628110](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015152628110.png)

Skip之后，点击OK，进入下面这个界面，点击next

![image-20201015152745005](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015152745005.png)

选择简体中文，选择美国英语式

![image-20201015152843063](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015152843063.png)

![image-20201015152908639](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015152908639.png)

选择基本存储设备

![image-20201015153017693](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153017693.png)

选择忽略所有数据

![image-20201015153113655](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153113655.png)

主机名随便取

![image-20201015153223022](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153223022.png)

一直下一步，直到输入密码界面，一般统一输入123456，然后无论如何都使用（如果是工作用，不建议密码过于简单）

![image-20201015153405741](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153405741.png)

我是选择自定义布局，创建三个分区，一般swap要和虚拟机内存一样大，之后选择格式化，将修改写入磁盘

![image-20201015153521421](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153521421.png)

![image-20201015153625685](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153625685.png)

![image-20201015153757821](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153757821.png)

![image-20201015153827078](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153827078.png)

之后点击下一步，出现如下界面，选择“现在自定义”

![image-20201015153951902](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015153951902.png)

点击下一步，到如下界面，在基本系统里，把java平台取消（系统默认是勾选的），这个基本系统的条目里，只保留“基本”和“调试工具”；应用程序里，只保留“互联网浏览器”（浏览器默认是火狐）；语言支持里，选择“中文支持”；点击下一步等待安装；选择重新引导

![image-20201015154057053](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015154057053.png)

![image-20201015154546517](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015154546517.png)

![image-20201015154523493](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015154523493.png)

![image-20201015155220004](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015155220004.png)

之后一直点击“前进”，不需要做任何其他操作，直到如下界面，选择是。

![image-20201015155529537](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015155529537.png)

至此一个比较干净的虚拟机就已经创建好了

#### 1.4.安装jdk

之后进入虚拟机，账号为root，密码就是之前设置的123456

![image-20201015155940103](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015155940103.png)

有的人可能有强迫症，觉得这个界面没有全屏，接下来，搞定它。点击“虚拟机”，找到“安装VMware tools”，点击它；之后系统会下载一个vmwareTools的包，把包复制到系统下的tmp文件夹，解压它，可以手动解压（右键就能找到），也可以敲命令

![image-20201015160113158](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015160113158.png)

![image-20201015160220738](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015160220738.png)

输入以下命令，把压缩包给解压了,解压之后产生一个vmware-tools-distrib文件，进入这个文件,输入命令"./vmware-install.pl"，之后一路enter或者"yes",安装完成之后，reboot



```
cd /tmp                #进入文件tmp
ls                     #查看该文件夹下的文件
tar -zxvf VMwareTools-10.3.21-17772444.tar.gz 	#解压该文件
cd vmware-tools-distrib/						#进入vmware-tools-distrib
./vmware-install.pl                             #执行安装程序
reboot                                          #重启生效
```

结果如图（自己换了背景）：

![image-20201015162215257](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015162215257.png)

进入正题，开始安装jdk，配置jdk环境，首先查看系统中有没有自带的java,我们之前的工作做好的话，系统中是不会遗留java的

```
[root@neo4j01 ~]# java -version
```



![image-20201015162442896](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015162442896.png)

进入usr文件夹,创建java文件夹

```
[root@neo4j01 ~]# cd /usr/
[root@neo4j01 usr]# mkdir java
[root@neo4j01 usr]# ls
bin  games    java  lib64    local  share  tmp
etc  include  lib   libexec  sbin   src

```

把我们事先准备的jdk压缩包，直接拖到java文件夹下，还是两种解压方式，命令如下：

```
[root@neo4j01 usr]# cd java/
[root@neo4j01 java]# tar -zxvf jdk-8u131-linux-x64.tar.gz 
[root@neo4j01 java]# ls
jdk1.8.0_131  jdk-8u131-linux-x64.tar.gz
```

之后编辑profile文件，追加如下命令，保存退出。：

```
vim /etc/profile
///////////
export JAVA_HOME=/usr/java/jdk1.8.0_131
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
//////////斜杠中间的语句，要追加到profile文件中 其中jdk路径要使用jdk实际解压的路径
```

![image-20201015163600045](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015163600045.png)

使用source /etc/profile 命令使更改生效；查看java版本，出现java的版本，表示jdk环境变量配置成功

```
[root@neo4j01 java]# vim /etc/profile
[root@neo4j01 java]# java -version
bash: java: command not found
[root@neo4j01 java]# source /etc/profile
[root@neo4j01 java]# java -version
java version "1.8.0_131"
Java(TM) SE Runtime Environment (build 1.8.0_131-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)
[root@neo4j01 java]# 

```

### 2.虚拟机的克隆

上面的jdk环境已经配好，现在开始虚拟机克隆

![image-20201015164317621](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015164317621.png)

点击下一步，直到如下界面，选择“创建完整克隆”

![image-20201015164425599](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015164425599.png)

自己选择名字，选择存储位置，点击完成，等就完事儿了。我打算配置一主二从，所以要克隆两台。

![image-20201015164554842](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015164554842.png)

### 3.虚拟机IP相关设置

#### 3.1更改主机名

我的三个虚拟机依次设置为Neo-01,Neo-02,Neo-03 同时把Neo-01作为master，其余两个作为slave;更改主机名之后，reboot重启

```
//Neo-01
[root@neo4j01 桌面]# vi /etc/sysconfig/network
[root@neo4j01 桌面]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=Neo-01
[root@neo4j01 桌面]# hostname Neo-01

//Neo-02
[root@neo4j01 桌面]# vi /etc/sysconfig/network
[root@neo4j01 桌面]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=Neo-02
[root@neo4j01 桌面]# hostname Neo-02

//Neo-03
[root@neo4j01 桌面]# vi /etc/sysconfig/network
[root@neo4j01 桌面]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=Neo-03
[root@neo4j01 桌面]# hostname Neo-03

```

验证

```
[root@Neo-01 桌面]# hostname
Neo-01

[root@Neo-02 桌面]# hostname
Neo-02

[root@Neo-03 桌面]# hostname
Neo-03

```

#### 3.2配置hosts文件

查询个虚拟机的IP地址

```
[root@Neo-03 桌面]# ifconfig
//////////////////////////////////////
Neo-01的IP地址：192.168.111.140
Neo-02的IP地址：192.168.111.138
Neo-03的IP地址：192.168.111.139
```

更改hosts文件 三个虚拟机都要配置，保证三台虚拟机能互相ping通，本机和虚拟机也能ping通

```
[root@Neo-02 桌面]# vim /etc/hosts
[root@Neo-02 桌面]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.111.140	Neo-01
192.168.111.138 Neo-02
192.168.111.139 Neo-03

```

![image-20201015175211864](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015175211864.png)

![image-20201015175224945](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015175224945.png)

![image-20201015175244691](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015175244691.png)

![image-20201015175341988](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015175341988.png)

### 4.安装hadoop

#### 4.1创建相关文件夹

/home/hadoop

/home/hadoop/dfs

/home/hadoop/tmp

/home/hadoop/dfs/data

/home/hadoop/dfs/name

```
[root@Neo-01 桌面]# cd /home/
[root@Neo-01 home]# mkdir hadoop
[root@Neo-01 home]# cd hadoop/
[root@Neo-01 hadoop]# mkdir dfs
[root@Neo-01 hadoop]# mkdir tmp
[root@Neo-01 hadoop]# mkdir tmp/{data,name}
```

这一步骤在三个虚拟机都要做

```
Neo-02
//////////////////////
[root@Neo-02 桌面]# cd /home/
[root@Neo-02 home]# mkdir hadoop
[root@Neo-02 home]# cd hadoop/
[root@Neo-02 hadoop]# mkdir dfs
[root@Neo-02 hadoop]# mkdir tmp
[root@Neo-02 hadoop]# ls
dfs  tmp

Neo-03
////////////////////
[root@Neo-03 桌面]# cd /home/
[root@Neo-03 home]# mkdir hadoop
[root@Neo-03 home]# cd hadoop/
[root@Neo-03 hadoop]# mkdir dfs
[root@Neo-03 hadoop]# mkdir tmp
[root@Neo-03 hadoop]# ls
dfs  tmp
```

#### 4.2解压hadoop压缩包

将hadoop2.7.3压缩包拖进/home/hadoop

```
[root@Neo-01 hadoop]# ls
dfs  hadoop-2.7.3.tar.gz  tmp
```

解压该压缩包

```
[root@Neo-01 hadoop]# tar -zxvf hadoop-2.7.3.tar.gz 
[root@Neo-01 hadoop]# ls
dfs  hadoop-2.7.3  hadoop-2.7.3.tar.gz  tmp
```

这一步骤仅在Neo-01(master)配置

#### 4.3配置ssh免密登录

**一、先关闭防火墙，三台虚拟机都要执行这个操作**

**关闭命令：**

```bash
service iptables stop
```

**永久关闭防火墙：**

```bash
chkconfig iptables off1
```

**两个命令同时运行，运行完成后查看防火墙关闭状态 ：**

```
service iptables status
```

二、配置虚拟机之间免密登录

安装和启动ssh服务

我先查看虚拟机情况,发现已有ssh和rsync服务

```
[root@Neo-02 ~]# rpm -qa | grep openssh
openssh-clients-5.3p1-94.el6.x86_64
openssh-5.3p1-94.el6.x86_64
openssh-askpass-5.3p1-94.el6.x86_64
openssh-server-5.3p1-94.el6.x86_64
[root@Neo-02 ~]# rpm -qa | grep rsync
rsync-3.0.6-9.el6_4.1.x86_64
```

如果没有这两个服务，则安装

```
yum install ssh     //安装SSH协议
yum install rsync   //（rsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件）
```

启动服务

```
[root@Neo-01 ~]# service sshd restart
停止 sshd：                                                [确定]
正在启动 sshd：                                            [确定]

[root@Neo-02 ~]# service sshd restart
停止 sshd：                                                [确定]
正在启动 sshd：                                            [确定]

[root@Neo-03 ~]# service sshd restart
停止 sshd：                                                [确定]
正在启动 sshd：                                            [确定]

```

在Master节点上执行以下命令

```
[root@Neo-01 ~]# ssh-keygen -t rsa -P ''
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa): 
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
fa:39:3b:1e:c7:e7:46:79:12:ea:7a:c6:dc:88:ff:f1 root@Neo-01
The key's randomart image is:
+--[ RSA 2048]----+
|                 |
|                 |
|                 |
|            .    |
|        S  . o   |
|       . .. + .  |
|      . .=o+oo   |
|       .++Booo   |
|       .*O.oo E  |
+-----------------+
[root@Neo-01 ~]# 
```

然后是修改文件夹”.ssh”的用户权限，把它的权限修改为”700”，用下面命令执行

```
[root@Neo-01 ~]# chmod 700 ~/.ssh
[root@Neo-01 ~]# 

```

接着在Master节点上做如下配置，把id_rsa.pub追加到授权的key里面去

```
[root@Neo-01 ~]# cd ~/.ssh
[root@Neo-01 .ssh]# cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
[root@Neo-01 .ssh]# ls
authorized_keys  id_rsa  id_rsa.pub
[root@Neo-01 .ssh]# 
```

**修改文件”authorized_keys”**，命令如下。如果不进行设置，在验证时，仍然提示你输入密码。

```
[root@Neo-01 .ssh]# chmod 600 ~/.ssh/authorized_keys
[root@Neo-01 .ssh]# ll
总用量 12
-rw-------. 1 root root  393 10月 16 02:31 authorized_keys
-rw-------. 1 root root 1675 10月 16 02:29 id_rsa
-rw-r--r--. 1 root root  393 10月 16 02:29 id_rsa.pub
[root@Neo-01 .ssh]# 

```

**设置SSH配置**
**用root**用户登录服务器修改SSH配置文件”/etc/ssh/sshd_config”的下列内容。

```
[root@Neo-01 .ssh]# vi /etc/ssh/sshd_config 
////////////////////////////
RSAAuthentication yes   //启用 RSA 认证
PubkeyAuthentication yes    //启用公钥私钥配对认证方式
AuthorizedKeysFile .ssh/authorized_keys //公钥文件路径（和上面生成的文件同）
```

设置完之后记得重启SSH服务，才能使刚才设置有效

```
[root@Neo-01 .ssh]# service sshd restart
停止 sshd：                                                [确定]
正在启动 sshd：                                            [确定]
[root@Neo-01 .ssh]# 

```

最后把将每个节点中的id_rsa.pub追加到其他节点的文件中

```
[root@Neo-01 .ssh]# ssh-copy-id Neo-01
[root@Neo-01 .ssh]# ssh-copy-id Neo-02
[root@Neo-01 .ssh]# ssh-copy-id Neo-03
//////////////////////////////////////////////////////
[root@Neo-01 .ssh]# ssh-copy-id Neo-01
The authenticity of host 'neo-01 (192.168.111.140)' can't be established.
RSA key fingerprint is 3a:61:0c:57:6a:c5:ff:ce:5d:e3:70:66:23:6a:83:12.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'neo-01,192.168.111.140' (RSA) to the list of known hosts.
Now try logging into the machine, with "ssh 'Neo-01'", and check in:

  .ssh/authorized_keys

to make sure we haven't added extra keys that you weren't expecting.

[root@Neo-01 .ssh]# ssh-copy-id Neo-02
The authenticity of host 'neo-02 (192.168.111.138)' can't be established.
RSA key fingerprint is 3a:61:0c:57:6a:c5:ff:ce:5d:e3:70:66:23:6a:83:12.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'neo-02,192.168.111.138' (RSA) to the list of known hosts.
root@neo-02's password: 
Now try logging into the machine, with "ssh 'Neo-02'", and check in:

  .ssh/authorized_keys

to make sure we haven't added extra keys that you weren't expecting.

[root@Neo-01 .ssh]# ssh-copy-id Neo-03
The authenticity of host 'neo-03 (192.168.111.139)' can't be established.
RSA key fingerprint is 3a:61:0c:57:6a:c5:ff:ce:5d:e3:70:66:23:6a:83:12.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'neo-03,192.168.111.139' (RSA) to the list of known hosts.
root@neo-03's password: 
Now try logging into the machine, with "ssh 'Neo-03'", and check in:

  .ssh/authorized_keys

to make sure we haven't added extra keys that you weren't expecting.

[root@Neo-01 .ssh]# 

```

其他节点的配置和上面相同，最后达到的效果是：集群内任何一个节点都能无密码登录上集群中的任意节点。

验证

```
[root@Neo-01 .ssh]# ssh Neo-01
Last login: Fri Oct 16 02:56:55 2020 from neo-02
[root@Neo-01 ~]# logout
Connection to Neo-01 closed.
[root@Neo-01 .ssh]# ssh Neo-02
Last login: Fri Oct 16 02:57:03 2020 from neo-02
[root@Neo-02 ~]# logout
Connection to Neo-02 closed.
[root@Neo-01 .ssh]# ssh Neo-03
Last login: Fri Oct 16 02:57:08 2020 from neo-02
[root@Neo-03 ~]# logout
Connection to Neo-03 closed.
[root@Neo-01 .ssh]# 

[root@Neo-02 ~]#  ssh Neo-01
Last login: Fri Oct 16 02:56:15 2020 from neo-03
[root@Neo-01 ~]# logout
Connection to Neo-01 closed.
[root@Neo-02 ~]#  ssh Neo-02
Last login: Fri Oct 16 02:56:24 2020 from neo-03
[root@Neo-02 ~]# logout
Connection to Neo-02 closed.
[root@Neo-02 ~]#  ssh Neo-03
Last login: Fri Oct 16 02:56:35 2020 from neo-03
[root@Neo-03 ~]# logout
Connection to Neo-03 closed.
[root@Neo-02 ~]# 


[root@Neo-03 .ssh]# ssh Neo-01
Last login: Fri Oct 16 02:50:54 2020 from neo-02
[root@Neo-01 ~]# logout
Connection to Neo-01 closed.
[root@Neo-03 .ssh]# ssh Neo-02
Last login: Fri Oct 16 02:52:10 2020 from neo-02
[root@Neo-02 ~]# logout
Connection to Neo-02 closed.
[root@Neo-03 .ssh]# ssh Neo-03
Last login: Fri Oct 16 02:54:57 2020 from localhost
[root@Neo-03 ~]# logout
Connection to Neo-03 closed.
[root@Neo-03 .ssh]# 


```

#### 4.4 配置hadoop环境变量

在/etc/profile中追加

export HADOOP_HOME=/home/hadoop/hadoop-2.7.3
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

上面路径要和hadoop2.7.3解压路径一致

命令如下

```
[root@Neo-01 ~]# vi /etc/profile
[root@Neo-01 ~]# source /etc/profile
///////////////////////////////////////
export HADOOP_HOME=/home/hadoop/hadoop-2.7.3
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
//////////////////////////////////////
反斜杠之间为追加内容
```

![image-20201015190755114](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015190755114.png)

验证,出现hadoop的版本信息 则环境变量配置成功

```
[root@Neo-01 ~]# hadoop
Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]
  CLASSNAME            run the class named CLASSNAME
 or
  where COMMAND is one of:
  fs                   run a generic filesystem user client
  version              print the version
  jar <jar>            run a jar file
                       note: please use "yarn jar" to launch
                             YARN applications, not this command.
  checknative [-a|-h]  check native hadoop and compression libraries availability
  distcp <srcurl> <desturl> copy file or directories recursively
  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive
  classpath            prints the class path needed to get the
  credential           interact with credential providers
                       Hadoop jar and the required libraries
  daemonlog            get/set the log level for each daemon
  trace                view and modify Hadoop tracing settings

Most commands print help when invoked w/o parameters.
[root@Neo-01 ~]# hadoop version
Hadoop 2.7.3
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff
Compiled by root on 2016-08-18T01:41Z
Compiled with protoc 2.5.0
From source with checksum 2e4ce5f957ea4db193bce3734ff29ff4
This command was run using /home/hadoop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar
[root@Neo-01 ~]# 

```

#### 4.5修改hadoop配置文件

文件位置：/home/hadoop/hadoop-2.7.3/etc/hadoop，

文件名称：hadoop-env.sh、yarn-evn.sh、slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、 yarn-site.xml

进入/home/hadoop/hadoop-2.7.3/etc/hadoop

```
[root@Neo-01 ~]# cd /home/
[root@Neo-01 home]# cd hadoop/
[root@Neo-01 hadoop]# cd hadoop-2.7.3
[root@Neo-01 hadoop-2.7.3]# ls
bin  etc  include  lib  libexec  LICENSE.txt  NOTICE.txt  README.txt  sbin  share
[root@Neo-01 hadoop-2.7.3]# cd etc/
[root@Neo-01 etc]# ls
hadoop
[root@Neo-01 etc]# cd hadoop/
[root@Neo-01 hadoop]# ls
capacity-scheduler.xml  hadoop-env.cmd              hadoop-policy.xml        httpfs-signature.secret  kms-log4j.properties  mapred-env.sh               ssl-client.xml.example  yarn-site.xml
configuration.xsl       hadoop-env.sh               hdfs-site.xml            httpfs-site.xml          kms-site.xml          mapred-queues.xml.template  ssl-server.xml.example
container-executor.cfg  hadoop-metrics2.properties  httpfs-env.sh            kms-acls.xml             log4j.properties      mapred-site.xml.template    yarn-env.cmd
core-site.xml           hadoop-metrics.properties   httpfs-log4j.properties  kms-env.sh               mapred-env.cmd        slaves                      yarn-env.sh
[root@Neo-01 hadoop]# vi hadoop-env.sh 

```

（1）配置hadoop-env.sh文件

修改JAVA_HOME为JAVA的安装路径

export JAVA_HOME=/usr/java/jdk1.8.0_131/

按照自己jdk实际路径

```
[root@Neo-01 hadoop]# vi hadoop-env.sh 
/////////////////////////////////////////////////////////////////////////////////
# The java implementation to use.
#export JAVA_HOME=${JAVA_HOME}
export JAVA_HOME=/usr/java/jdk1.8.0_131/

```

（2）配置yarn-env.sh文件

指定yran框架的java运行环境，该文件是yarn框架运行环境的配置文件，需要修改JAVA_HOME的位置

```
[root@Neo-01 hadoop]# vi yarn-env.sh 
//////////////////////////////////////////////////////////////
# some Java parameters
# export JAVA_HOME=/home/y/libexec/jdk1.6.0/
export JAVA_HOME=/usr/java/jdk1.8.0_131/

if [ "$JAVA_HOME" != "" ]; then

```

（3）配置slaves文件

Neo-02,Neo-03作为从主机

```
[root@Neo-01 hadoop]# vi slaves
[root@Neo-01 hadoop]# cat slaves
Neo-02
Neo-03
You have mail in /var/spool/mail/root
[root@Neo-01 hadoop]# 
```

我采用是完全分布式

（4）修改core-site.xml文件，注意蓝色标注的内容

```xml
<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://Neo-01:9000</value>
</property>
<property>
<name>io.file.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>file:/home/hadoop/tmp</value>
<description>Abase for other temporary directories.</description>
</property>
</configuration>
```

（5）修改hdfs-site.xml文件

```xml
<configuration>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>Neo-01:9001</value>
<description># 通过web界面来查看HDFS状态 </description>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/home/hadoop/dfs/name</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/home/hadoop/dfs/data</value>
</property>
<property>
<name>dfs.replication</name>
<value>2</value>
<description># 每个Block有2个备份</description>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
</configuration>
```

（6）修改mapred-site.xml

这个是mapreduce任务的配置，由于hadoop2.x使用了yarn框架，所以要实现分布式部署，必须在mapreduce.framework.name属性下配置为yarn。mapred.map.tasks和mapred.reduce.tasks分别为map和reduce的任务数

```xml
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
<property>
<name>mapreduce.jobhistory.address</name>
<value>Neo-01:10020</value>
</property>
<property>
<name>mapreduce.jobhistory.webapp.address</name>
<value>Neo-01:19888</value>
</property>
</configuration>
```

7）配置节点yarn-site.xml

\#该文件为yarn架构的相关配置

```xml
<configuration>
<!-- Site specific YARN configuration properties -->
<property>
<name>yarn.resourcemanager.hostname</name>
<value>Neo-01</value>
</property>
 slavee
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<property>
<name>yarn.resourcemanager.address</name>
<value>Neo-01:8032</value>
</property>
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>Neo-01:8030</value>
</property>
<property>
<name>yarn.resourcemanager.resource-tracker.address</name>
<value>Neo-01:8031</value>
</property>
<property>
<name>yarn.resourcemanager.admin.address</name>
<value>Neo-01:8033</value>
</property>
<property>
<name>yarn.resourcemanager.webapp.address</name>
<value>Neo-01:8088</value>
</property>
<property>
<name>yarn.nodemanager.resource.memory-mb</name>
<value>8192</value>
</property>
</configuration>
```

#### 4.6复制hadoop到其他节点

命令如下：

```
scp -r /home/hadoop/hadoop-2.7.3/ 192.168.111.138:/home/hadoop/
scp -r /home/hadoop/hadoop-2.7.3/ 192.168.111.139:/home/hadoop/
```

#### 4.7 在Neo-01中进行初始化

```
[root@Neo-01 桌面]# /home/hadoop/hadoop-2.7.3/bin/hdfs namenode -format
///////////////////////////////////////////////////////////////////////////
20/10/16 06:34:31 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Neo-01/192.168.111.140
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/hadoop-2.7.3/etc/hadoop:/home/hadoop/hadoop-
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_131
************************************************************/

20/10/16 06:34:32 INFO util.GSet: VM type       = 64-bit
20/10/16 06:34:32 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
20/10/16 06:34:32 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/10/16 06:34:32 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1593362957-192.168.111.140-1602801272618
20/10/16 06:34:32 INFO common.Storage: Storage directory /home/hadoop/dfs/name has been successfully formatted.
20/10/16 06:34:32 INFO namenode.FSImageFormatProtobuf: Saving image file /home/hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression
20/10/16 06:34:32 INFO namenode.FSImageFormatProtobuf: Image file /home/hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 350 bytes saved in 0 seconds.
20/10/16 06:34:32 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
20/10/16 06:34:32 INFO util.ExitUtil: Exiting with status 0
20/10/16 06:34:32 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Neo-01/192.168.111.140
************************************************************/

```

#### 4.8 启动hadoop

```
[root@Neo-01 桌面]# start-dfs.sh
Starting namenodes on [Neo-01]
Neo-01: starting namenode, logging to /home/hadoop/hadoop-2.7.3/logs/hadoop-root-namenode-Neo-01.out
Neo-03: starting datanode, logging to /home/hadoop/hadoop-2.7.3/logs/hadoop-root-datanode-Neo-03.out
Neo-02: starting datanode, logging to /home/hadoop/hadoop-2.7.3/logs/hadoop-root-datanode-Neo-02.out
Starting secondary namenodes [Neo-01]
Neo-01: starting secondarynamenode, logging to /home/hadoop/hadoop-2.7.3/logs/hadoop-root-secondarynamenode-Neo-01.out
[root@Neo-01 桌面]# start-yarn.sh
starting yarn daemons
starting resourcemanager, logging to /home/hadoop/hadoop-2.7.3/logs/yarn-root-resourcemanager-Neo-01.out
Neo-02: starting nodemanager, logging to /home/hadoop/hadoop-2.7.3/logs/yarn-root-nodemanager-Neo-02.out
Neo-03: starting nodemanager, logging to /home/hadoop/hadoop-2.7.3/logs/yarn-root-nodemanager-Neo-03.out

```

检测进程

```
[root@Neo-01 桌面]# jps
4034 ResourceManager
4295 Jps
3672 NameNode
3883 SecondaryNameNode
```

验证：

打开火狐浏览器,输入Neo-01:50070 进入Hadoop的主页面，点击DateNodes,如果能看到节点：Neo-02和Neo-03，表明配置成功

![image-20201015224852292](C:/Users/MNH/AppData/Roaming/Typora/typora-user-images/image-20201015224852292.png)

以上是Centos6.5版本下的hadoop完全分布式集群安装方式，Centos更高版本和Ubuntu的操作命令或有有些许不同，打大同小异